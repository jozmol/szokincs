<!doctype html>
<html lang="hu">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>Kiejt√©s gyakorl√≥ ‚Äî Du√°l m√≥d (Chromium / Firefox)</title>
<style>
  *{box-sizing:border-box}
  body{font-family:Segoe UI,system-ui,Arial;margin:0;background:linear-gradient(135deg,#667eea,#764ba2);min-height:100vh;display:flex;align-items:center;justify-content:center;padding:20px;color:#222}
  .card{width:100%;max-width:900px;background:#fff;border-radius:12px;box-shadow:0 10px 30px rgba(0,0,0,.2);overflow:hidden}
  header{background:linear-gradient(90deg,#ff7a18,#af0d1f);color:#fff;padding:22px;text-align:center}
  header h1{margin:0;font-size:1.6rem}
  .body{padding:20px}
  .row{display:flex;gap:12px;flex-wrap:wrap;align-items:center}
  select,button,input{font-size:1rem;padding:10px;border-radius:8px;border:1px solid #ccc}
  button{cursor:pointer;background:#1976d2;color:#fff;border:none}
  .controls{margin-top:12px;display:flex;gap:10px;flex-wrap:wrap}
  .status{margin-top:12px;padding:10px;border-radius:8px;background:#f1f3f5;color:#333}
  .feedback{margin-top:12px;padding:12px;border-radius:8px}
  .bars{display:flex;gap:8px;align-items:flex-end;height:160px;padding:10px;border:1px solid #eee;border-radius:8px;overflow-x:auto;background:#fafafa}
  .bar-col{display:flex;flex-direction:column;align-items:center;gap:4px;width:18px}
  .bar{width:100%;background:#2196f3;border-radius:4px;transition:height .2s}
  .bar.ref{background:#90caf9}
  .bar.user{background:#4caf50}
  .legend{display:flex;gap:12px;margin-top:8px;align-items:center}
  .legend .dot{width:12px;height:12px;border-radius:3px;display:inline-block}
  .controls button.secondary{background:#ff9800}
  .controls button.ghost{background:#607d8b}
  .small{font-size:.9rem;color:#555}
  @media(max-width:600px){.bars{height:120px}.bar-col{width:12px}}
</style>
</head>
<body>
  <div class="card" role="application">
    <header>
      <h1>Kiejt√©s Gyakorl√≥ ‚Äî Du√°l m√≥d (Chromium / Firefox)</h1>
      <div class="small">Chrome/Edge: besz√©dfelismer√©s. Firefox: vizu√°lis + sz√°zal√©kos hangmint√°s √∂sszevet√©s.</div>
    </header>

    <div class="body">
      <div class="row">
        <label for="wordCount">Szavak sz√°ma:</label>
        <select id="wordCount">
          <option value="5">5</option>
          <option value="7" selected>7</option>
          <option value="10">10</option>
          <option value="0">All</option>
        </select>

        <button id="startBtn">üöÄ Start</button>
        <button id="nextBtn" class="secondary">‚û°Ô∏è Next</button>
        <button id="listenBtn" class="ghost">üîä Play (TTS)</button>
      </div>

      <div id="progress" class="status" style="display:none;margin-top:12px"></div>

      <div id="wordCard" style="margin-top:16px;display:none">
        <div style="font-size:2rem;color:#d32f2f;font-weight:700" id="targetWord">‚Äî</div>
        <div style="color:#666;margin-top:6px" id="targetInfo">‚Äî</div>

        <div class="controls">
          <button id="recordBtn">üé§ Start Recording</button>
          <button id="stopBtn" disabled>‚èπ Stop</button>
          <button id="analyzeBtn" disabled>üîç Analyze</button>
        </div>

        <div id="recordingStatus" class="status" style="display:block;margin-top:12px">Ready</div>

        <div id="visualSection" style="margin-top:14px;display:none">
          <div><strong>Visual comparison (Reference vs User)</strong></div>
          <div class="bars" id="barsContainer" aria-hidden="false"></div>
          <div class="legend">
            <div><span class="dot" style="background:#90caf9"></span> Reference (TTS)</div>
            <div><span class="dot" style="background:#4caf50"></span> User</div>
            <div style="margin-left:auto;font-weight:bold">Match: <span id="matchPct">0%</span></div>
          </div>
        </div>

        <div id="feedback" class="feedback"></div>
      </div>

      <div style="margin-top:18px;color:#666;font-size:.95rem">
        <p><strong>Megjegyz√©s:</strong> Chrome / Edge eset√©n a b√∂ng√©sz≈ë be√©p√≠tett besz√©dfelismer√©s√©t haszn√°ljuk ‚Äî enged√©lyezd a mikrofont. Firefoxban a rendszer TTS-et lej√°tssza referenciahangk√©nt, majd a felhaszn√°l√≥ felmond√°sa alapj√°n egy egyszer≈± energia-elemz√©st √©s vizualiz√°ci√≥t kap.</p>
      </div>
    </div>
  </div>

<script>
/* ---------- Adatok (sz√≥t√°r) ---------- */
const fullWordDictionary = [
  {english:"thank you", pinyin:"thank you", meaning:"Ë∞¢Ë∞¢"},
  {english:"good day", pinyin:"good day", meaning:"‰Ω†Â•Ω"},
  {english:"I love you", pinyin:"I love you", meaning:"ÊàëÁà±‰Ω†"},
  {english:"hello", pinyin:"hello", meaning:"‰Ω†Â•Ω"},
  {english:"water", pinyin:"water", meaning:"Ê∞¥"},
  {english:"mother", pinyin:"mother", meaning:"Â¶àÂ¶à"},
  {english:"friend", pinyin:"friend", meaning:"ÊúãÂèã"},
  {english:"breakfast", pinyin:"breakfast", meaning:"Êó©È§ê"},
  {english:"lunch", pinyin:"lunch", meaning:"ÂçàÈ§ê"},
  {english:"dinner", pinyin:"dinner", meaning:"ÊôöÈ§ê"},
  {english:"soup", pinyin:"soup", meaning:"Ê±§"},
  {english:"salad", pinyin:"salad", meaning:"Ê≤ôÊãâ"}
];

/* ---------- DOM ---------- */
const startBtn = document.getElementById('startBtn');
const nextBtn = document.getElementById('nextBtn');
const listenBtn = document.getElementById('listenBtn');
const recordBtn = document.getElementById('recordBtn');
const stopBtn = document.getElementById('stopBtn');
const analyzeBtn = document.getElementById('analyzeBtn');
const recordingStatus = document.getElementById('recordingStatus');
const targetWordEl = document.getElementById('targetWord');
const targetInfoEl = document.getElementById('targetInfo');
const wordCard = document.getElementById('wordCard');
const progressEl = document.getElementById('progress');
const barsContainer = document.getElementById('barsContainer');
const visualSection = document.getElementById('visualSection');
const matchPctEl = document.getElementById('matchPct');
const feedbackEl = document.getElementById('feedback');
const wordCountSelect = document.getElementById('wordCount');

let selectedWords = [];
let currentIndex = 0;

/* ---------- Detection: Chromium vs Firefox ---------- */
const isFirefox = typeof InstallTrigger !== 'undefined';
const isChromiumSpeech = !!(window.SpeechRecognition || window.webkitSpeechRecognition);

/* ---------- SpeechRecognition (Chromium) ---------- */
let recognizer = null;
if (isChromiumSpeech) {
  try {
    const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
    recognizer = new SR();
    recognizer.interimResults = false;
    recognizer.maxAlternatives = 1;
    recognizer.lang = 'en-US';
  } catch (e) {
    recognizer = null;
  }
}

/* ---------- Audio / MediaRecorder (for both modes) ---------- */
let mediaRecorder = null;
let audioChunks = [];
let isRecording = false;
let audioContext = null;

/* ---------- Utility helpers ---------- */
function pickRandomWords(n) {
  if (!n || n===0) return [...fullWordDictionary];
  const arr = [...fullWordDictionary].sort(()=>0.5-Math.random());
  return arr.slice(0, Math.min(n, arr.length));
}
function updateProgress() {
  progressEl.style.display = 'block';
  progressEl.textContent = `${currentIndex+1}/${selectedWords.length}`;
}
function cleanVisuals(){
  barsContainer.innerHTML = '';
  visualSection.style.display = 'none';
  matchPctEl.textContent = '0%';
  feedbackEl.innerHTML = '';
}

/* ---------- Reference envelope generator (simple) ----------
   We cannot capture system TTS output reliably across browsers.
   So we:
   - play the TTS to user (for reference),
   - measure its duration (start->end),
   - build a synthetic "reference energy envelope" based on syllable/vowel count and duration.
   This gives a visually comparable envelope.
---------------------------------------------- */
function estimateSyllableCount(word){
  // very simple vowel groups count heuristic
  const v = word.toLowerCase().match(/[aeiouy]+/g);
  return v ? Math.max(1, v.length) : 1;
}
function makeReferenceEnvelope(word, durationMs, bins=30){
  const syllables = estimateSyllableCount(word);
  // create envelope with `syllables` peaks spaced across bins
  const env = new Array(bins).fill(0);
  for (let s=0;s<syllables;s++){
    const center = Math.floor((s+0.5)*bins/syllables);
    const width = Math.max(1, Math.floor(bins/(syllables*1.6)));
    for (let i=0;i<bins;i++){
      const d = Math.abs(i-center);
      env[i] += Math.max(0, (1 - (d/width)));
    }
  }
  // normalize to 0..1
  const maxv = Math.max(...env);
  if (maxv>0) for (let i=0;i<env.length;i++) env[i] = env[i]/maxv;
  return env;
}

/* ---------- Audio envelope extractor ----------
   Decode recorded audio Blob to PCM and compute short-time energy in N bins
---------------------------------------------- */
async function getAudioEnvelopeFromBlob(blob, bins=30){
  if (!audioContext) audioContext = new (window.AudioContext || window.webkitAudioContext)();
  const arrayBuffer = await blob.arrayBuffer();
  const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
  const channelData = audioBuffer.getChannelData(0);
  const len = channelData.length;
  const binSize = Math.floor(len / bins);
  const env = new Array(bins).fill(0);
  for (let b=0;b<bins;b++){
    const start = b*binSize;
    let sum = 0;
    const end = (b === bins-1) ? len : start + binSize;
    for (let i=start;i<end;i++){
      const v = channelData[i];
      sum += v*v;
    }
    const rms = Math.sqrt(sum / (end-start+1));
    env[b] = rms;
  }
  // normalize 0..1
  const maxv = Math.max(...env);
  if (maxv>0) for (let i=0;i<env.length;i++) env[i] = env[i]/maxv;
  return env;
}

/* ---------- Similarity metric (cosine similarity) ---------- */
function cosineSimilarity(a,b){
  if (!a || !b || a.length !== b.length) return 0;
  let dot=0, na=0, nb=0;
  for (let i=0;i<a.length;i++){
    dot += a[i]*b[i];
    na += a[i]*a[i];
    nb += b[i]*b[i];
  }
  if (na===0 || nb===0) return 0;
  return dot / (Math.sqrt(na)*Math.sqrt(nb));
}

/* ---------- Visualization: draw bins side-by-side ---------- */
function drawBars(refEnv, userEnv){
  barsContainer.innerHTML = '';
  visualSection.style.display = 'block';
  const bins = Math.max(refEnv.length, userEnv.length);
  for (let i=0;i<bins;i++){
    const col = document.createElement('div');
    col.className='bar-col';
    // reference bar
    const bref = document.createElement('div');
    bref.className='bar ref';
    const rH = Math.round((refEnv[i]||0)*100);
    bref.style.height = (rH)+'%';
    // user bar (overlay below)
    const buser = document.createElement('div');
    buser.className='bar user';
    const uH = Math.round((userEnv[i]||0)*100);
    buser.style.height = (uH)+'%';
    // place reference above user (visual stacking)
    col.appendChild(bref);
    col.appendChild(buser);
    barsContainer.appendChild(col);
  }
}

/* ---------- Core flows ---------- */

// Display current word
function displayCurrentWord(){
  if (!selectedWords.length) return;
  const w = selectedWords[currentIndex];
  targetWordEl.textContent = w.english;
  targetInfoEl.textContent = `Pinyin: ${w.pinyin || '-'} ‚Äî Meaning: ${w.meaning || '-'}`;
  cleanVisuals();
  updateProgress();
}

// Play TTS and measure duration (returns duration ms)
function playTTSAndMeasure(text){
  return new Promise((resolve)=>{
    if (!('speechSynthesis' in window)){
      // fallback approximate duration
      const approx = Math.max(600, text.length*80);
      resolve(approx);
      return;
    }
    const ut = new SpeechSynthesisUtterance(text);
    ut.lang = 'en-US';
    ut.rate = 0.95;
    let start = null;
    ut.onstart = ()=> start = performance.now();
    ut.onend = ()=> {
      const end = performance.now();
      const dur = Math.max(200, Math.round(end - (start||end)));
      resolve(dur);
    };
    // speak
    window.speechSynthesis.cancel();
    window.speechSynthesis.speak(ut);
  });
}

/* ---------- Recording control (both modes use MediaRecorder) ---------- */
async function startRecording(){
  try{
    recordingStatus.textContent = 'üîÑ Accessing microphone...';
    const stream = await navigator.mediaDevices.getUserMedia({ audio:true });
    audioChunks = [];
    mediaRecorder = new MediaRecorder(stream);
    mediaRecorder.ondataavailable = e => { if (e.data && e.data.size>0) audioChunks.push(e.data); };
    mediaRecorder.onstop = ()=> {
      recordingStatus.textContent = '‚úÖ Recording saved (ready to analyze)';
      analyzeBtn.disabled = false;
      // stop tracks
      stream.getTracks().forEach(t=>t.stop());
    };
    mediaRecorder.start();
    isRecording = true;
    recordBtn.disabled = true;
    stopBtn.disabled = false;
    analyzeBtn.disabled = true;
    recordingStatus.textContent = 'üî¥ Recording... Speak now!';
    // if Chromium speech recog available, start recognizer too (optional)
    if (recognizer){
      try{ recognizer.start(); }catch(e){}
      recognizer.onresult = function(ev){
        const text = ev.results[0][0].transcript;
        recordingStatus.textContent = `üó£ Recognized: "${text}"`;
      };
    }
  }catch(err){
    console.error('Recording error', err);
    recordingStatus.textContent = '‚ùå Microphone access denied or error';
    feedbackEl.innerHTML = '<div style="color:#d32f2f">Please allow microphone access and retry.</div>';
  }
}
function stopRecording(){
  if (!mediaRecorder) return;
  if (isRecording && mediaRecorder.state !== 'inactive'){
    mediaRecorder.stop();
    isRecording = false;
    recordBtn.disabled = false;
    stopBtn.disabled = true;
    recordingStatus.textContent = '‚èπ Stopped';
    try{ if (recognizer) recognizer.stop(); }catch(e){}
  }
}

/* ---------- Analyze behaviour:
   - If Chromium & SpeechRecognition available, prefer STT path: use last transcript (from recognizer.onresult)
   - If Firefox (or recog not supported), perform audio-based comparison:
       1. play TTS and measure duration -> create synthetic ref envelope
       2. record user audio (we already have blob) -> extract envelope
       3. compute cosine similarity -> show bars + pct
---------------------------------------------- */

async function analyzeRecordingFlow(){
  recordingStatus.textContent = 'üîç Analyzing...';
  feedbackEl.innerHTML = '';
  // If Chromium & recognizer available: attempt to use last recognized transcript
  if (recognizer && !isFirefox){
    // Try to obtain a transcript from recognizer result (if any)
    // We rely on recordingStatus text set earlier; better: attach onresult storing lastTranscript
    // For simplicity: prompt fallback if no recognized text present
    let transcript = null;
    // try to parse recordingStatus text for Recognized: "text"
    const match = recordingStatus.textContent.match(/Recognized:\s*"(.+)"$/);
    if (match) transcript = match[1];
    if (!transcript){
      // Ask user to type fallback
      transcript = window.prompt('No reliable recognition result. Type what you pronounced (fallback):');
      if (!transcript){ recordingStatus.textContent='‚ö† No input provided'; return; }
    }
    const target = selectedWords[currentIndex].english.toLowerCase();
    const scoreObj = phoneticCompare(transcript.toLowerCase(), target);
    showPhoneticResult(scoreObj, transcript, target);
    return;
  }

  // FIREFOX / audio-based path
  // 1) ensure we have a recording blob
  if (!audioChunks || audioChunks.length === 0){
    recordingStatus.textContent = '‚ö† No recording found. Please record first.';
    return;
  }
  // 2) Play TTS and measure duration (we'll build ref envelope from vowel heuristics)
  const target = selectedWords[currentIndex].english;
  recordingStatus.textContent = '‚ñ∂ Playing reference (TTS)...';
  const ttsDuration = await playTTSAndMeasure(target);
  recordingStatus.textContent = `‚è± Reference played (${Math.round(ttsDuration)} ms). Processing...`;

  // 3) Get reference envelope
  const bins = 30;
  const refEnv = makeReferenceEnvelope(target, ttsDuration, bins);

  // 4) Get user envelope from recorded blob
  const blob = new Blob(audioChunks, {type: audioChunks[0].type || 'audio/webm'});
  const userEnv = await getAudioEnvelopeFromBlob(blob, bins);

  // 5) Compute similarity
  const sim = cosineSimilarity(refEnv, userEnv);
  const pct = Math.round(sim*100);

  // 6) Show bars and percent
  drawBars(refEnv, userEnv);
  matchPctEl.textContent = `${pct}%`;
  feedbackEl.innerHTML = `<div style="font-weight:bold">${pct}% match (based on energy envelope)</div>
    <div class="small" style="margin-top:6px">This is an approximate acoustic similarity (good for basic pronunciation practice in Firefox).</div>`;
  recordingStatus.textContent = '‚úÖ Analysis complete';
  analyzeBtn.disabled = false;
  visualSection.style.display = 'block';
}

/* ---------- Small phonetic compare used in Chromium path ---------- */
const phoneticDictionary = {
  "hello":["helo","helou","halo","hellou","ellow"],
  "thank you":["tenk ju","sank ju","thank yu","tenk you","sank you"],
  "good day":["gud dei","gud day","good dei","gud dey"],
  "i love you":["ai lav ju","ay lov you","i lav yu"],
  "water":["voter","vater","woter"],
  "mother":["mader","mather","moter"],
  "friend":["frend","frind","freind"],
  "breakfast":["brekfast"],
  "lunch":["lancs","lanch"],
  "dinner":["diner","dine"]
};
function simpleSimilarity(a,b){
  if (!a||!b) return 0;
  a=a.toLowerCase().trim(); b=b.toLowerCase().trim();
  if (a===b) return 1;
  // check phonetic variants
  const variants = phoneticDictionary[b]||[];
  if (variants.includes(a)) return 0.85;
  // char-match heuristic
  const minLen = Math.min(a.length,b.length);
  let matches=0;
  for (let i=0;i<minLen;i++) if (a[i]===b[i]) matches++;
  return matches / Math.max(a.length,b.length);
}
function phoneticCompare(spoken,target){
  const s = simpleSimilarity(spoken,target);
  if (s>=0.9) return {match:true,score:95,type:'perfect'};
  if (s>=0.75) return {match:true,score:80,type:'good'};
  if (s>=0.5) return {match:true,score:60,type:'partial'};
  // Hungarian detection (basic)
  if (/[√°√©√≠√≥√∂≈ë√∫√º≈±]|sz|zs|cs|gy|ty|ny|ly/.test(spoken)) return {match:false,score:15,type:'hungarian'};
  return {match:false,score:30,type:'no_match'};
}
function showPhoneticResult(res, spoken, target){
  let color='#ff9800', msg='Try again';
  if (res.type==='perfect'){ color='#4caf50'; msg='Perfect!'; }
  else if (res.match){ color='#4caf50'; msg='Good!'; }
  else if (res.type==='hungarian'){ color='#d32f2f'; msg='Please speak English'; }
  feedbackEl.innerHTML = `<div style="font-weight:bold;color:${color}">${msg}</div>
    <div style="margin-top:8px">You said: "${spoken}"<br>Target: "${target}"</div>
    <div style="margin-top:8px">Score: <strong>${res.score}%</strong> | Type: ${res.type}</div>`;
}

/* ---------- Event wiring ---------- */
startBtn.addEventListener('click', ()=>{
  const n = parseInt(wordCountSelect.value);
  selectedWords = pickRandomWords(n===0?fullWordDictionary.length:n);
  currentIndex = 0;
  displayCurrentWord();
  wordCard.style.display = 'block';
  progressEl.style.display = 'block';
  updateProgress();
  cleanVisuals();
});

nextBtn.addEventListener('click', ()=>{
  if (!selectedWords.length) return;
  currentIndex = (currentIndex+1) % selectedWords.length;
  displayCurrentWord();
});

listenBtn.addEventListener('click', ()=> {
  const w = selectedWords[currentIndex];
  if (!w) return;
  playTTSAndMeasure(w.english);
});

recordBtn.addEventListener('click', startRecording);
stopBtn.addEventListener('click', stopRecording);
analyzeBtn.addEventListener('click', async ()=> {
  analyzeBtn.disabled = true;
  await analyzeRecordingFlow();
});

/* ---------- Accessibility: keyboard hint ---------- */
document.addEventListener('keydown', (e)=>{
  if (e.key===' ' && document.activeElement===recordBtn) { e.preventDefault(); if (!isRecording) startRecording(); else stopRecording(); }
});

/* ---------- Init ---------- */
(function init(){
  // Preload nothing; show note about mode
  if (isFirefox){
    recordingStatus.textContent = 'Firefox detected: audio-based visual analysis will be used (TTS + recording).';
  } else if (recognizer){
    recordingStatus.textContent = 'Chromium speech recognition enabled: STT-based evaluation will be used.';
  } else {
    recordingStatus.textContent = 'SpeechRecognition not available; fallback to audio visual analysis will be used.';
  }
})();
</script>
</body>
</html>
